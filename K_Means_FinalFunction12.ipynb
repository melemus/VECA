{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cd958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38539dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanthsaiyeddulapalli/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KMeans from version 1.2.1 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def get_cluster_labels(data):\n",
    "    # Load the KMeans Clustering algorithm\n",
    "    kmeans = load('KMeans_NodeClustering.joblib')\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # One-hot encode the 'Type' column\n",
    "    #type_dummies = pd.get_dummies(df['Type'], prefix='Type')\n",
    "\n",
    "    # Drop the original 'Type' column and concatenate the one-hot encoded columns\n",
    "    df_encoded = pd.concat([df.drop('Node', axis=1)], axis=1)\n",
    "\n",
    "    # Convert DataFrame to numpy array\n",
    "    X = df_encoded.values\n",
    "\n",
    "    # Standardize the data to have a mean of ~0 and a variance of 1\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Determine the cluster labels of each point\n",
    "    labels = kmeans.predict(X_scaled)\n",
    "\n",
    "    # Add the cluster labels as a column to the original DataFrame\n",
    "    df_encoded['Cluster'] = labels\n",
    "\n",
    "    return df_encoded['Cluster'].values\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df is your DataFrame\n",
    "data = [\n",
    "#     {'Node': 'VEC-Master', 'RAM (GB)': 4, 'Storage (GB)': 20, 'CPU (Cores)': 2,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':0,'Security Score (0-10)': 8},\n",
    "    {'Node': 'VEC_VEN1', 'RAM (GB)': 0.5, 'Storage (GB)': 8, 'CPU (Cores)': 1,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':1, 'Security Score (0-10)': 8},\n",
    "    {'Node': 'VEC_VEN2', 'RAM (GB)': 1, 'Storage (GB)': 12, 'CPU (Cores)': 1,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':0, 'Security Score (0-10)': 8},\n",
    "    {'Node': 'VEC_VEN3', 'RAM (GB)': 2, 'Storage (GB)': 16, 'CPU (Cores)': 1,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':1, 'Security Score (0-10)': 8},\n",
    "    {'Node': 'VEC_VEN4', 'RAM (GB)': 4, 'Storage (GB)': 12, 'CPU (Cores)': 2,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':0, 'Security Score (0-10)': 8},\n",
    "    {'Node': 'VEC_VEN5', 'RAM (GB)': 4, 'Storage (GB)': 30, 'CPU (Cores)': 2,'Type_Cache':0,'Type_Compute': 1,'Type_Storage':0, 'Security Score (0-10)': 8}\n",
    "]\n",
    "\n",
    "result_cluster = get_cluster_labels(data)\n",
    "print(result_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fac303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
